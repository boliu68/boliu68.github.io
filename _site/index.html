<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Latest Posts &#8211; Long Long Later</title>
<meta name="description" content="Describe this nonsense.">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Latest Posts">
<meta property="og:description" content="Describe this nonsense.">
<meta property="og:url" content="http://boliu68.github.io/index.html">
<meta property="og:site_name" content="Long Long Later">





<link rel="canonical" href="http://boliu68.github.io/">
<link href="http://boliu68.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Long Long Later Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://boliu68.github.io/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://boliu68.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://boliu68.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://boliu68.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://boliu68.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://boliu68.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://boliu68.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://boliu68.github.io/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://boliu68.github.io/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://boliu68.github.io/images/head.jpg" alt="Bo Liu photo" class="author-photo">
					<h4>Bo Liu</h4>
					<p>Machine Learning, PhD student</p>
				</li>
				<li><a href="http://boliu68.github.io/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:6liubo8@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				
				
				<li>
					<a href="http://linkedin.com/in/https://hk.linkedin.com/pub/bo-brody-liu/55/52b/10b"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://boliu68.github.io/posts/">All Posts</a></li>
				<li><a href="http://boliu68.github.io/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  <div class="image-credit">Image source: <a href="http://www.dargadgetz.com/ios-7-abstract-wallpaper-pack-for-iphone-5-and-ipod-touch-retina/">dargadgetz</a></div><!-- /.image-credit -->
  
    <div class="entry-image">
      <img src="http://boliu68.github.io/images/abstract-1.jpg" alt="Latest Posts">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Long Long Later</h1>
      <h2>Latest Posts</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-09-10T00:00:00-04:00"><a href="http://boliu68.github.io/Savage's%20approach%20to%20research/">September 10, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="http://boliu68.github.io/about/" title="About Bo Liu">Bo Liu</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
        Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://boliu68.github.io/Savage's%20approach%20to%20research/" rel="bookmark" title="Savage's approach to research" itemprop="url">Savage's approach to research</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Savage’s approach to research, via Mosteller（copy from Jon McAuliffe’s and Jun Liu’s webpage):</p>

<ul>
  <li>As soon as a problem is stated, start right away to solve it. Use simple examples.</li>
  <li>Keep starting from <strong>first principles</strong>, explaining again and again what you are trying to do.</li>
  <li><strong>Believe</strong> that this problem can be solved and that you will enjoy working it out.</li>
  <li>Don’t be hampered by the original problem statement. Try other problems in its neighborhood; maybe there is a better problem than yours.</li>
  <li>Work an hour or so on it frequently. Talk about it; explain it to people.</li>
</ul>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-09-08T00:00:00-04:00"><a href="http://boliu68.github.io/Notes%20on%20Sure%20screening%20interaction%20selection/">September 08, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="http://boliu68.github.io/about/" title="About Bo Liu">Bo Liu</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
        Reading time ~2 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://boliu68.github.io/Notes%20on%20Sure%20screening%20interaction%20selection/" rel="bookmark" title="Notes on Sure Screening interaction selection" itemprop="url">Notes on Sure Screening interaction selection</a></h1>
    
  </header>
  <div class="entry-content">
    <h4 id="lee-s-lozano-a-kambadur-p--xing-e-p-2015-april-an-efficient-nonlinear-regression-approach-for-genome-wide-detection-of-marginal-and-interacting-genetic-variations">Lee, S., Lozano, A., Kambadur, P., &amp; Xing, E. P. (2015, April). An Efficient Nonlinear Regression Approach for Genome-Wide Detection of Marginal and Interacting Genetic Variations.</h4>

<ul>
  <li>Summary in my own understanding:</li>
</ul>

<ol>
  <li>A screening algorithm based on iterative sure independent screening theory.
    <ul>
      <li>The marginal and the pairs are all evaluated using cheap method. And the top features or pairs are selected. <strong><em>Although this save a lot of computation, for high order interactions more than 2nd order, it is still exponential that is not acceptable.</em></strong></li>
    </ul>
  </li>
  <li>After the few SNPs and interactions are selected. We solve the effects of each SNPs or interactions. To consider the nonlinear relationship of interactions. The piecewise linear model is utilized.</li>
  <li>To control the false positive, for different parameter, we randomly sampled <script type="math/tex">\frac{N}{2}​</script> samples and run piecewise linear model on this part of data.
    <ul>
      <li>As the number of false positive can be bounded according to our parameter <strong><em>supported by stable selection theory</em></strong>, we choose a small subset of SNPs and pairs that satisfy  the false positive requirement.</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Evaluation Metrics
    <ul>
      <li>False positive control</li>
      <li>Statistical power</li>
      <li>Screening scalability</li>
    </ul>
  </li>
</ul>

<h4 id="fan-y-kong-y-li-d--zheng-z-2015-innovated-interaction-screening-for-high-dimensional-nonlinear-classificationthe-annals-of-statistics433-1243-1272">Fan, Y., Kong, Y., Li, D., &amp; Zheng, Z. (2015). Innovated interaction screening for high-dimensional nonlinear classification. <em>The Annals of Statistics</em>, <em>43</em>(3), 1243-1272.</h4>

<p>Summary in my own understanding</p>

<h6 id="some-assumptions">Some assumptions:</h6>

<ul>
  <li>The theory works for Gaussian <strong>two-class Gaussian classification</strong> problem.</li>
</ul>

<script type="math/tex; mode=display">z=\triangle z_1 + (1-\triangle)z_2\\
z_1 \text{ and } z_2 \sim N(\mu_1,\Sigma_1) \text{ and } N(\mu_2, \Sigma_2) \text{ respectively}\\
\triangle \sim Ber(\pi)</script>

<ul>
  <li>The min and max eigenvalue of covariance if bounded.</li>
</ul>

<script type="math/tex; mode=display">\tau_1\leq \lambda_{min}(\Sigma_k)\leq\lambda_{max}(\Sigma_k)\leq\tau_p</script>

<ul>
  <li>The variance of different class can be distinguished.</li>
  <li><script type="math/tex">\Sigma_1^{-1}</script> and <script type="math/tex">\Sigma_2^{-1}</script> are both <script type="math/tex">K_p</script> sparse. And <script type="math/tex">l_\infty(\Sigma_k^{-1})</script> is bounded.</li>
  <li>​</li>
</ul>

<h6 id="methods">Methods:</h6>

<ul>
  <li>Reduce the number of interactions to a moderate order by a new inter- action screening approach</li>
  <li>Identify both important main effects and interactions using some variable selection techniques</li>
  <li>An interaction screening criteria that can be proved to enjoy sure screening property.</li>
</ul>

<h6 id="interaction-screening-method">Interaction screening method</h6>

<ol>
  <li>For binary classification problem, the importance of single feature to interaction is attributed as the difference of variance of two classes.
    <ul>
      <li>Transform the feature space by using <script type="math/tex">\Sigma_1^{-1}x</script>  (where <script type="math/tex">\Sigma_1</script> denote the covariance of samples in class <script type="math/tex">1</script>). And similarly, we also transform the original features using <script type="math/tex">\Sigma_2^{-1}x</script> .</li>
      <li>In the new feature space, the difference between variance of two class represents how important the single feature is for interaction.</li>
    </ul>
  </li>
</ol>

<h6 id="sure-screening-property">Sure screening property</h6>

<h6 id="when-sigma-1-is-known">When <script type="math/tex">\Sigma^{-1}</script> is known</h6>

<ul>
  <li>​</li>
</ul>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-05-10T00:00:00-04:00"><a href="http://boliu68.github.io/ReadList%20of%20Distributed%20Optimization%20Algorithms/">May 10, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="http://boliu68.github.io/about/" title="About Bo Liu">Bo Liu</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
        Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://boliu68.github.io/ReadList%20of%20Distributed%20Optimization%20Algorithms/" rel="bookmark" title="Readlist of Distributed Optimization Algorithm" itemprop="url">Readlist of Distributed Optimization Algorithm</a></h1>
    
  </header>
  <div class="entry-content">
    <p>[1] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trend in Machine Learning, 3(1):1–122, 2011.</p>

<p>[2] Joseph K Bradley, Aapo Kyrola, Danny Bickson, and Carlos Guestrin. Par- allel coordinate descent for l1-regularized loss minimization. arXiv preprint arXiv:1105.5379, 2011.</p>

<p>[3] Weizhu Chen, Zhenghao Wang, and Jingren Zhou. Large-scale l-bfgs using mapreduce. In Advances in Neural Information Processing Systems, pages 1332–1340, 2014.</p>

<p>[4] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et al. Large scale distributed deep networks. In Advances in Neural Information Processing Systems, pages 1223–1231, 2012.</p>

<p>[5] Yi Wang, Hongjie Bai, Matt Stanton, Wen-Yen Chen, and Edward Y Chang. Plda: Parallel latent dirichlet allocation for large-scale applications. In Al- gorithmic aspects in information and management, pages 301–314. Springer, 2009.</p>

<p>[6] Yong Zhuang, Wei-Sheng Chin, Yu-Chin Juan, and Chih-Jen Lin. Dis- tributed newton method for regularized logistic regression. Department of Computer Science and Information Engineering, National Taiwan University, Tech. Rep, 2014.</p>

<p>[7] Martin Zinkevich, Markus Weimer, Lihong Li, and Alex J Smola. Par- allelized stochastic gradient descent. In Advances in Neural Information Processing Systems, pages 2595–2603, 2010.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-03-11T00:00:00-04:00"><a href="http://boliu68.github.io/differential%20privacy%20and%20machine%20learning/">March 11, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="http://boliu68.github.io/about/" title="About Bo Liu">Bo Liu</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
        Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://boliu68.github.io/differential%20privacy%20and%20machine%20learning/" rel="bookmark" title="Differential Privacy and Machine Learning" itemprop="url">Differential Privacy and Machine Learning</a></h1>
    
  </header>
  <div class="entry-content">
    <p>As a begining of my research, I survey the topics on differential privacy and machine learning. The basic structure of this slide is arised from [1].</p>

<p>Some very important topics in differential privacy machine learning containing in</p>

<ol>
  <li>The local sensitivity and smooth sensitivity.</li>
  <li>The utility of mechansim.</li>
  <li>The relationship of differential privacy with learning theory.</li>
</ol>

<p>is not covered in this slides.</p>

<p>The slides: click here <a href="https://github.com/boliu68/boliu68.github.io/blob/master/res/differential_privacy_machine_learing.pdf?raw=true">2</a></p>

<hr />
<p>Referenecs:</p>

<p>[1] Ji, Z., Lipton, Z. C., &amp; Elkan, C. (2014). Differential Privacy and Machine Learning: a Survey and Review. Learning; Cryptography and Security; Databases.</p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-12-04T00:00:00-05:00"><a href="http://boliu68.github.io/LR,%20Spark,%20SGD%20and%20Big%20Data/">December 04, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://boliu68.github.io/about/" title="About Bo Liu">Bo Liu</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
        Reading time ~3 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://boliu68.github.io/LR,%20Spark,%20SGD%20and%20Big%20Data/" rel="bookmark" title="LR, Spark, SGD and Big Data" itemprop="url">LR, Spark, SGD and Big Data</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Logistic Regression(<a href="http://en.wikipedia.org/wiki/Logistic_regression">LR</a>) serves as a simple but competitive algorithm for classifiation. LR is effective to train and widely utilized online for recommendation, ads and rankings. In this blog, I will demonstrate my experience of LR algorithm based on Stochastic Gradient Descent(<a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD</a>), <a href="https://spark.apache.org/">Spark</a> for quite big dataset. The method is based on python. Some python packages such as numpy, scipy as well as sklearn is utlized for efficiency. It will not be difficult to transfer to other platform, in my opinion.</p>

<p>The so called big data, in this post, represents billions instance(10e9) and billions dimensions(10e8). No doubt that the dimension is very very sparse. On average, only 64 non-zero entries exist for each instance. Concerned about many issuse ^-^. I only talks about pseudo-cdoe as follows.</p>

<pre><code>Spark_LR(dataset)
#dataset: #instnaces * #dimension
#parameters: #partitions,#parallelism
1 Read data and split each line, repartition the dataset
2 Build the hash map for features
3 Dummy(intersection) the features and record the non-zero coordinate/value
4
5 #building csr_matrix in scipy is expensive in both memory and computation.
6 data_rdd = spark.MapPartitions(convert to scipy.csr_matrix).cache()
7 count the #instance, #dimension etc.
8
9 while not converge
10  #depend on l1 or l2 norm is used
11 	para_rdd = data_rdd.MapPartitions(SGD(using sklearn))
12	average all the parameters learnt by SGD
</code></pre>

<p>The pseudo-code is very very simple. But it cost me a lot of time to make this work on billions instances. Based on some following experience, LR can handle billions-dataset on a cluster with 240 cpu cores and 640 GB memory in total. However, the disk space is also a bottleneck that I will metion later.</p>

<h2 id="tips-and-experiences">Tips and experiences:</h2>

<p><strong>Line 1</strong>: repartition() function in pyspark results in a more balance partitions. However, repartition requires too much computation, memory as well as disk for shuffle. After several attempts, I will never utilize repartition() directly on such large dataset.</p>

<p><strong>Line 3</strong>: Maybe particular for python using scipy.sparse package. Building csr_matrix is quite expensive. Thus, instead of building csr_matrix for each instance again and again. We will directly map each partition to a big csr_matrix.</p>

<p><strong>Line 6</strong>: Converting the large dataset to a big csr_matrix run out of memory several times as well. Thus, in the final version code, I serialize to building several smaller csr_matrix and concat in the last. This will trade some time for memory. But I believe it is worth as you cannot guarantee how large the dataset will be.</p>

<p>Storage.MEMORY_AND_DISK is suggested in my opinion to persist. Intuitively, this results in crazy usage of disk space. However, compared to the usage by shuffle metioned later, this is acceptable.</p>

<p><strong>Line 11</strong>: I just call sklearn.linear_model.SGDClassifier to do SGD in each partitions. No doubt that you can implement one yourself which should be more fun.</p>

<p>One of biggest challenge here is that the high-dimension(10e8) parameters vectors obtained from each partitions has to be averaged. Calling sum(), reduce() lead to calling a collect(). This means, in my experiment, collecting 100GB sparse vector back to master. Obviously, this is not acceptable. As a result, for <script type="math/tex">w_i</script> obtain in partition <script type="math/tex">i</script>, I partition <script type="math/tex">w_i</script> to #parallesim. For instance <script type="math/tex">w_i \rightarrow (1,w\_{i,1}), (2,w\_{i,2})\dots(k,w\_{i,k})</script>. <script type="math/tex">k</script> denotes the k which is identical for all the partitions. Afterwards, reduceByKey is called to sum up all the resul and only one parameter vector is collected back.</p>

<p>Furthermore, a serious side effect is that we change the key in doing the above trick. And each time, for instance, 100GB(400 partitions * 300MB sparse vector) hash to be shuffled and write to disk. For really many times, my disk is running out. I try to compress the shuffle by flush the shuffle files to hdfs. But both does not work well.</p>

<p>No doubt that fewer partition will alleviate this problems. However, few partitions means that you have to use fewer cpus to avoid the memory is running out. Quite several time have to be attempted.</p>

<p>In total, to avoid keeping all the dataset in memory, I follows the guidance in <a href="http://blog.smola.org/post/977927287/parallel-stochastic-gradient-descent">blog of Alex Smola</a> that</p>

<blockquote>
  <p>We overpartition the dataset and using a fixed learning rate for SGD.</p>
</blockquote>

<p>This is the mechanism I implements, the majority of time is costed on tricks and debugging. I have no idea how to test and dubug when the problems can only occur when large dataset.</p>

<p>Moreover, I would be appreciated if you can offer me some discussion or hints caused, currently, the disk usage, memory usage and cpu usage is not perfect. Only very few cpus are used for memory concerne. Moreover, if you can inspire me to avoid the shuffling of realling huge data of parameters vectors. I will also be appreciated.</p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->


<div class="pagination">
  
    Previous
  
  <ul class="inline-list">
    <li>
      
        <span class="current-page">1</span>
      
    </li>
    
      <li>
        
          <a href="http://boliu68.github.io/page2">2</a>
        
      </li>
    
  </ul>
  
    <a href="http://boliu68.github.io/page2" class="btn">Next</a>
  
</div><!-- /.pagination -->
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2015 Bo Liu. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://boliu68.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://boliu68.github.io/assets/js/scripts.min.js"></script>



          

</body>
</html>