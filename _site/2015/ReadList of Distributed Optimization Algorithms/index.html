<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Your New Jekyll Site - Readlist of Distributed Optimization Algorithm</title>
  <link rel="shortcut icon" href="/assets/images/favicon.ico">
  <link rel="stylesheet" href="/assets/css/style.css">
  <link rel="alternate" type="application/rss+xml" title="My Blog" href="/rss.xml">
  <link rel="stylesheet" href="/assets/css/highlight.css">
</head>
<body>

  <nav class="main-nav">
    
        <a href="/"> <span class="arrow">←</span> Home </a>
    

    
        
            <a href="/about">About </a>
        
    
    <a class="cta" href="/feed.xml">Subscribe</a>
</nav>

  

  <section id="wrapper" class="">
    <article class="post">
    <header>
        <h1>Readlist of Distributed Optimization Algorithm</h1>
        <h2 class="headline">May 10, 2015</h2>
    </header>
    <section id="post-body">
        <p>[1] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trend in Machine Learning, 3(1):1–122, 2011.</p>

<p>[2] Joseph K Bradley, Aapo Kyrola, Danny Bickson, and Carlos Guestrin. Par- allel coordinate descent for l1-regularized loss minimization. arXiv preprint arXiv:1105.5379, 2011.</p>

<p>[3] Weizhu Chen, Zhenghao Wang, and Jingren Zhou. Large-scale l-bfgs using mapreduce. In Advances in Neural Information Processing Systems, pages 1332–1340, 2014.</p>

<p>[4] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et al. Large scale distributed deep networks. In Advances in Neural Information Processing Systems, pages 1223–1231, 2012.</p>

<p>[5] Yi Wang, Hongjie Bai, Matt Stanton, Wen-Yen Chen, and Edward Y Chang. Plda: Parallel latent dirichlet allocation for large-scale applications. In Al- gorithmic aspects in information and management, pages 301–314. Springer, 2009.</p>

<p>[6] Yong Zhuang, Wei-Sheng Chin, Yu-Chin Juan, and Chih-Jen Lin. Dis- tributed newton method for regularized logistic regression. Department of Computer Science and Information Engineering, National Taiwan University, Tech. Rep, 2014.</p>

<p>[7] Martin Zinkevich, Markus Weimer, Lihong Li, and Alex J Smola. Par- allelized stochastic gradient descent. In Advances in Neural Information Processing Systems, pages 2595–2603, 2010.</p>

    </section>
</article>
<footer id="post-meta" class="clearfix">
    <a href="http://twitter.com/YourTwitterUsername">
        <img class="avatar" src="/assets/images/avatar.png">
        <div>
            <span class="dark">Bo Liu</span>
            <span>Blogging about stuffs</span>
        </div>
    </a>

    <section id="sharing">
        <a class="twitter" href="https://twitter.com/intent/tweet?text=http://boliu68.github.io//2015/ReadList%20of%20Distributed%20Optimization%20Algorithms/ - Readlist of Distributed Optimization Algorithm by @YourTwitterUsername"><span class="icon-twitter"> Tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>
    </section>
</footer>

<!-- Disqus comments -->


<!-- Archive post list -->

    <ul id="post-list" class="archive readmore">
        <h3>Read more</h3>
        
            <li>
                <a href="/2015/Savage's%20approach%20to%20research/">Savage's approach to research<aside class="dates">Sep 10</aside></a>
            </li>
        
            <li>
                <a href="/2015/Notes%20on%20Sure%20screening%20interaction%20selection/">Notes on Sure Screening interaction selection<aside class="dates">Sep 08</aside></a>
            </li>
        
            <li>
                <a href="/2015/ReadList%20of%20Distributed%20Optimization%20Algorithms/">Readlist of Distributed Optimization Algorithm<aside class="dates">May 10</aside></a>
            </li>
        
            <li>
                <a href="/2015/differential%20privacy%20and%20machine%20learning/">Differential Privacy and Machine Learning<aside class="dates">Mar 11</aside></a>
            </li>
        
            <li>
                <a href="/2014/LR,%20Spark,%20SGD%20and%20Big%20Data/">LR, Spark, SGD and Big Data<aside class="dates">Dec 04</aside></a>
            </li>
        
            <li>
                <a href="/2014/CDCF%20Reading%20list/">Readlist of Cross-Domain Collaborative Filtering<aside class="dates">Nov 19</aside></a>
            </li>
        
            <li>
                <a href="/2014/how%20to%20compile%20OpenCV%20without%20root/">How to compile opencv on linux without root<aside class="dates">Oct 28</aside></a>
            </li>
        
            <li>
                <a href="/2014/What%20means%20by%20Sparsity%3F/">What mean by sparsity?<aside class="dates">Oct 14</aside></a>
            </li>
        
    </ul>





  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script src="/assets/js/main.js"></script>
  <script src="/assets/js/highlight.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXXX-X', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>



