---
layout: post
categories: [gradient boosting, adaboost]
---

#Gradient boosting and Adaboost?
---

For a quite long time, I am confused what exactly mean by gradient boosting. Altough the based idea is quite simple. Moreover, it is well known that the Adaboost can be understood in the perspective of gradient descent of exponential loss. In this blog, I will record why called gradient boosting. I think the gradient boosting page at Wikipedia is quite clear to understand. Thus, I will not illustrate the idea and just demonstrate the required equations.
